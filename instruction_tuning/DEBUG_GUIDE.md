# PDB è°ƒè¯•æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¯¼èˆª

**æƒ³æŸ¥çœ‹VLMçš„è¾“å‡ºï¼Ÿç›´æ¥è·³åˆ°è¿™ä¸¤ä¸ªæ–­ç‚¹ï¼š**
- â­ **æ–­ç‚¹4.5**: VLMè¾“å…¥å‡†å¤‡å®Œæˆ - æŸ¥çœ‹é€å…¥æ¨¡å‹çš„æ•°æ®
- â­â­ **æ–­ç‚¹5**: VLMè¾“å‡º - æŸ¥çœ‹æ¨¡å‹é¢„æµ‹ç»“æœå’Œlogitsï¼ˆæœ€é‡è¦ï¼ï¼‰

---

## å·²æ·»åŠ çš„æ–­ç‚¹ä½ç½®

### æ–­ç‚¹1: `sft_tool.py` - mainå‡½æ•°å…¥å£ (ç¬¬215è¡Œ)
**ä½ç½®**: mainå‡½æ•°å¼€å§‹å¤„  
**ç›®çš„**: æŸ¥çœ‹æ‰€æœ‰å¯åŠ¨å‚æ•°  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# åœ¨pdbä¸­è¾“å…¥è¿™äº›å‘½ä»¤æŸ¥çœ‹:
print(script_args)      # è„šæœ¬å‚æ•°
print(training_args)    # è®­ç»ƒå‚æ•°
print(model_args)       # æ¨¡å‹å‚æ•°
print(model_args.model_name_or_path)  # æ¨¡å‹è·¯å¾„
```

### æ–­ç‚¹2: `sft_tool.py` - æ•°æ®åŠ è½½å®Œæˆ (ç¬¬234è¡Œ)
**ä½ç½®**: æ•°æ®é›†åŠ è½½å  
**ç›®çš„**: æŸ¥çœ‹æ•°æ®é›†å†…å®¹å’Œæ ¼å¼  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# æŸ¥çœ‹æ•°æ®é›†
print(len(train_dataset))        # æ•°æ®é›†å¤§å°
print(train_dataset[0])          # ç¬¬ä¸€ä¸ªæ ·æœ¬
print(train_dataset.data[:3])    # å‰3ä¸ªæ ·æœ¬

# æŸ¥çœ‹æ•°æ®ç»“æ„
import json
print(json.dumps(train_dataset[0], indent=2, ensure_ascii=False))
```

### æ–­ç‚¹3: `sft_tool.py` - Traineråˆå§‹åŒ–å®Œæˆ (ç¬¬261è¡Œ)
**ä½ç½®**: traineråˆ›å»ºåï¼Œè®­ç»ƒå¼€å§‹å‰  
**ç›®çš„**: æŸ¥çœ‹traineré…ç½®å’Œæ¨¡å‹çŠ¶æ€  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# æŸ¥çœ‹traineré…ç½®
print(trainer.args)              # è®­ç»ƒå‚æ•°
print(trainer.model)             # æ¨¡å‹ç»“æ„
print(trainer.vlm_module)        # VLMæ¨¡å—

# æŸ¥çœ‹æ¨¡å‹å‚æ•°
total_params = sum(p.numel() for p in trainer.model.parameters())
trainable_params = sum(p.numel() for p in trainer.model.parameters() if p.requires_grad)
print(f"æ€»å‚æ•°: {total_params:,}")
print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

# æŸ¥çœ‹å†»ç»“çš„å‚æ•°
for name, param in trainer.model.named_parameters():
    if not param.requires_grad:
        print(f"å†»ç»“: {name}")
```

### æ–­ç‚¹4: `sft_tooltrainer.py` - compute_losså¼€å§‹ (ç¬¬372è¡Œ)
**ä½ç½®**: æ¯ä¸ªè®­ç»ƒbatchçš„lossè®¡ç®—å‰  
**ç›®çš„**: æŸ¥çœ‹å®é™…è¾“å…¥æ•°æ®å’Œå¤„ç†æµç¨‹  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# æŸ¥çœ‹batchå†…å®¹
print(len(inputs))               # batch size
print(inputs[0].keys())          # æ•°æ®å­—æ®µ
print(message_lists[0])          # ç¬¬ä¸€ä¸ªæ¶ˆæ¯åˆ—è¡¨

# æŸ¥çœ‹è®¾å¤‡å’Œåˆ†å¸ƒå¼ä¿¡æ¯
print(device)
print(self.accelerator.process_index)
```

### æ–­ç‚¹4.5: `sft_tooltrainer.py` - VLMè¾“å…¥å‡†å¤‡å®Œæˆ (ç¬¬386è¡Œ)
**ä½ç½®**: VLMè¾“å…¥å‡†å¤‡å®Œæˆåï¼Œæ¨¡å‹forwardå‰  
**ç›®çš„**: æŸ¥çœ‹ä¼ å…¥VLMçš„è¾“å…¥å¼ é‡ç»“æ„  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# æŸ¥çœ‹VLMè¾“å…¥ç»“æ„
print(inputs.keys())                    # è¾“å…¥å­—æ®µï¼ˆå¦‚input_ids, pixel_valuesç­‰ï¼‰
print(inputs.input_ids.shape)           # è¾“å…¥tokençš„å½¢çŠ¶
print(inputs.attention_mask.shape)      # attention maskå½¢çŠ¶

# å¦‚æœæœ‰å›¾åƒè¾“å…¥
if hasattr(inputs, 'pixel_values'):
    print(inputs.pixel_values.shape)    # å›¾åƒç‰¹å¾å½¢çŠ¶
if hasattr(inputs, 'image_grid_thw'):
    print(inputs.image_grid_thw.shape)  # å›¾åƒç½‘æ ¼ä¿¡æ¯

# æŸ¥çœ‹å®é™…çš„input tokensï¼ˆè§£ç æŸ¥çœ‹ï¼‰
batch_idx = 0
tokens = inputs.input_ids[batch_idx]
decoded = self.processing_class.tokenizer.decode(tokens)
print(f"è¾“å…¥æ–‡æœ¬:\n{decoded}")
```

### æ–­ç‚¹5: `sft_tooltrainer.py` - VLMè¾“å‡º (ç¬¬233è¡Œ) â­ é‡ç‚¹
**ä½ç½®**: VLMæ¨¡å‹forwardåï¼Œè·å¾—logits  
**ç›®çš„**: æŸ¥çœ‹VLMçš„å®é™…è¾“å‡ºå’Œé¢„æµ‹ç»“æœ  
**å¯ä»¥æ£€æŸ¥çš„å†…å®¹**:
```python
# æŸ¥çœ‹è¾“å‡ºå½¢çŠ¶
print(f"Logits shape: {logits.shape}")  # (batch_size, seq_len, vocab_size)
print(f"Input IDs shape: {input_ids.shape}")

# æŸ¥çœ‹æ¨¡å‹é¢„æµ‹çš„tokenï¼ˆè´ªå©ªè§£ç ï¼‰
predicted_ids = logits.argmax(dim=-1)   # è·å–æ¦‚ç‡æœ€é«˜çš„token
print(f"Predicted IDs shape: {predicted_ids.shape}")

# è§£ç æŸ¥çœ‹æ¨¡å‹é¢„æµ‹çš„æ–‡æœ¬
batch_idx = 0
predicted_text = self.processing_class.tokenizer.decode(predicted_ids[batch_idx])
actual_text = self.processing_class.tokenizer.decode(input_ids[batch_idx])
print(f"\nå®é™…è¾“å…¥çš„æ–‡æœ¬:\n{actual_text}")
print(f"\næ¨¡å‹é¢„æµ‹çš„æ–‡æœ¬:\n{predicted_text}")

# æŸ¥çœ‹ç‰¹å®šä½ç½®çš„æ¦‚ç‡åˆ†å¸ƒ
pos = 10  # æŸ¥çœ‹ç¬¬10ä¸ªä½ç½®
top_k = 5
top_probs, top_indices = logits[batch_idx, pos].softmax(dim=-1).topk(top_k)
print(f"\nä½ç½®{pos}çš„top-{top_k}é¢„æµ‹:")
for prob, idx in zip(top_probs, top_indices):
    token = self.processing_class.tokenizer.decode([idx])
    print(f"  {token}: {prob.item():.4f}")

# æŸ¥çœ‹lossç›¸å…³çš„token
# æ‰¾åˆ°assistantçš„å›å¤éƒ¨åˆ†
assistant_mask = logits_to_keep[batch_idx]
assistant_positions = assistant_mask.nonzero().flatten()
print(f"\nAssistantå›å¤çš„tokenä½ç½®: {assistant_positions.tolist()}")
if len(assistant_positions) > 0:
    start = assistant_positions[0].item()
    end = min(start + 20, len(input_ids[batch_idx]))
    assistant_text = self.processing_class.tokenizer.decode(input_ids[batch_idx][start:end])
    print(f"Assistantå›å¤å†…å®¹: {assistant_text}")
```

## è¿è¡Œè°ƒè¯•

### 1. å¯åŠ¨è°ƒè¯•è„šæœ¬
```bash
cd /NEW_EDS/miaojw/projects/Pixel-Reasoner
bash instruction_tuning/sft-test-debug.sh
```

### 2. PDBå¸¸ç”¨å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `n` (next) | æ‰§è¡Œä¸‹ä¸€è¡Œ | `n` |
| `s` (step) | è¿›å…¥å‡½æ•°å†…éƒ¨ | `s` |
| `c` (continue) | ç»§ç»­æ‰§è¡Œåˆ°ä¸‹ä¸€ä¸ªæ–­ç‚¹ | `c` |
| `p` (print) | æ‰“å°å˜é‡ | `p train_dataset` |
| `pp` (pretty print) | æ ¼å¼åŒ–æ‰“å° | `pp train_dataset[0]` |
| `l` (list) | æ˜¾ç¤ºå½“å‰ä»£ç  | `l` |
| `w` (where) | æ˜¾ç¤ºè°ƒç”¨æ ˆ | `w` |
| `u` (up) | ä¸Šä¸€å±‚è°ƒç”¨æ ˆ | `u` |
| `d` (down) | ä¸‹ä¸€å±‚è°ƒç”¨æ ˆ | `d` |
| `q` (quit) | é€€å‡ºè°ƒè¯• | `q` |
| `h` (help) | å¸®åŠ© | `h` |

### 3. é«˜çº§æŠ€å·§

#### æŸ¥çœ‹å˜é‡ç±»å‹å’Œå±æ€§
```python
type(train_dataset)
dir(train_dataset)
vars(train_dataset)
```

#### æ‰§è¡Œå¤šè¡Œä»£ç 
```python
!import json
!with open('/tmp/debug.json', 'w') as f:
!    json.dump(train_dataset.data[0], f, indent=2)
```

#### æ¡ä»¶æ–­ç‚¹ï¼ˆåœ¨ä»£ç ä¸­è®¾ç½®ï¼‰
```python
if condition:
    import pdb; pdb.set_trace()
```

#### åŠ¨æ€ä¿®æ”¹å˜é‡
```python
(Pdb) script_args.per_device_train_batch_size = 2
```

## ç†è§£é¡¹ç›®æµç¨‹

1. **å¯åŠ¨æµç¨‹** (sft_tool.py):
   - è§£æå‘½ä»¤è¡Œå‚æ•° â†’ åŠ è½½æ•°æ®é›† â†’ åˆå§‹åŒ–VLMæ¨¡å— â†’ åˆ›å»ºTrainer â†’ å¼€å§‹è®­ç»ƒ

2. **è®­ç»ƒæµç¨‹** (sft_tooltrainer.py):
   - compute_lossè¢«å¾ªç¯è°ƒç”¨
   - æ¯ä¸ªbatch: è·å–æ¶ˆæ¯åˆ—è¡¨ â†’ å‡†å¤‡VLMè¾“å…¥ â†’ è®¡ç®—logits â†’ è®¡ç®—loss

3. **å…³é”®ç»„ä»¶**:
   - `VLMModule`: å°è£…æ¨¡å‹çš„å¤„ç†é€»è¾‘
   - `SFT_DATASET`: æ•°æ®é›†ç±»
   - `Qwen2VLSFTToolTrainer`: è®­ç»ƒå™¨ç±»

## å¿«é€Ÿè°ƒè¯•æ£€æŸ¥æ¸…å•

### åœ¨æ–­ç‚¹1æ£€æŸ¥:
- [ ] æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®
- [ ] æ•°æ®è·¯å¾„æ˜¯å¦æ­£ç¡®
- [ ] è®­ç»ƒå‚æ•°æ˜¯å¦ç¬¦åˆé¢„æœŸ

### åœ¨æ–­ç‚¹2æ£€æŸ¥:
- [ ] æ•°æ®é›†æ˜¯å¦æˆåŠŸåŠ è½½
- [ ] æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
- [ ] message_listç»“æ„æ˜¯å¦ç¬¦åˆé¢„æœŸ

### åœ¨æ–­ç‚¹3æ£€æŸ¥:
- [ ] æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
- [ ] visionæ¨¡å—æ˜¯å¦æ­£ç¡®å†»ç»“
- [ ] å¯è®­ç»ƒå‚æ•°æ•°é‡æ˜¯å¦æ­£ç¡®

### åœ¨æ–­ç‚¹4æ£€æŸ¥:
- [ ] batchæ•°æ®æ˜¯å¦æ­£ç¡®
- [ ] å›¾åƒæ˜¯å¦æ­£ç¡®åŠ è½½
- [ ] æ¶ˆæ¯æ ¼å¼æ˜¯å¦æ­£ç¡®

### åœ¨æ–­ç‚¹4.5æ£€æŸ¥:
- [ ] VLMè¾“å…¥å¼ é‡å½¢çŠ¶æ˜¯å¦æ­£ç¡®
- [ ] pixel_valuesæ˜¯å¦åŒ…å«å›¾åƒç‰¹å¾
- [ ] input_idsè§£ç åçš„æ–‡æœ¬æ˜¯å¦ç¬¦åˆé¢„æœŸ

### åœ¨æ–­ç‚¹5æ£€æŸ¥ï¼ˆâ­ æŸ¥çœ‹VLMè¾“å‡ºçš„æœ€ä½³ä½ç½®ï¼‰:
- [ ] logitså½¢çŠ¶æ˜¯å¦æ­£ç¡® (batch, seq_len, vocab_size)
- [ ] æ¨¡å‹é¢„æµ‹çš„æ–‡æœ¬æ˜¯å¦åˆç†
- [ ] é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒæ˜¯å¦æ­£å¸¸
- [ ] assistantå›å¤éƒ¨åˆ†æ˜¯å¦è¢«æ­£ç¡®è¯†åˆ«

## ç§»é™¤æ–­ç‚¹

å¦‚æœæƒ³ç§»é™¤æŸä¸ªæ–­ç‚¹ï¼Œæ³¨é‡Šæ‰æˆ–åˆ é™¤å¯¹åº”çš„è¿™ä¸€è¡Œ:
```python
import pdb; pdb.set_trace()  # æ–­ç‚¹X: ...
```

## æ³¨æ„äº‹é¡¹

1. **å•å¡è°ƒè¯•**: è°ƒè¯•è„šæœ¬å·²é…ç½®ä¸ºå•å¡æ¨¡å¼ï¼ˆCUDA_VISIBLE_DEVICES=1ï¼‰
2. **å†…å­˜ä½¿ç”¨**: è°ƒè¯•æ—¶æ³¨æ„GPUå†…å­˜ï¼Œå¯èƒ½éœ€è¦å‡å°batch_size
3. **æ–­ç‚¹4ä¼šé¢‘ç¹è§¦å‘**: æ¯ä¸ªbatchéƒ½ä¼šåœåœ¨æ–­ç‚¹4ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥æ³¨é‡Šæ‰
4. **åˆ†å¸ƒå¼è®­ç»ƒ**: å¦‚æœè¦è°ƒè¯•å¤šå¡ï¼Œéœ€è¦ä½¿ç”¨debugpyè€Œä¸æ˜¯pdb

## è¿›é˜¶: ä½¿ç”¨debugpyè¿›è¡Œè¿œç¨‹è°ƒè¯•

å¦‚æœéœ€è¦åœ¨VSCodeä¸­è°ƒè¯•å¤šå¡è®­ç»ƒï¼Œå¯ä»¥ä½¿ç”¨å·²ç»å¯¼å…¥çš„debugpyï¼ˆè§sft_tool.pyç¬¬18-53è¡Œï¼‰

