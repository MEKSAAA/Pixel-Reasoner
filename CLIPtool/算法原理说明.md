# WinCLIP ç®—æ³•åŸç†è¯´æ˜

## ğŸ“Š å¼‚å¸¸æ£€æµ‹æµç¨‹æ¦‚è¿°

WinCLIPä½¿ç”¨CLIPæ¨¡å‹è¿›è¡Œé›¶æ ·æœ¬/å°‘æ ·æœ¬å¼‚å¸¸æ£€æµ‹ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š

---

## 1ï¸âƒ£ ç‰¹å¾æå–

### æ–‡æœ¬ç‰¹å¾ï¼ˆText Featuresï¼‰
```python
# ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆä¸¤ç§æè¿°
normal_prompts = [
    "flawless bottle", 
    "perfect bottle",
    "bottle without defect",
    ...
]

abnormal_prompts = [
    "damaged bottle",
    "bottle with flaw",
    "bottle with defect",
    ...
]

# æå–æ–‡æœ¬ç‰¹å¾å¹¶å¹³å‡
normal_text_features = CLIP.encode_text(normal_prompts)  # [N, D]
abnormal_text_features = CLIP.encode_text(abnormal_prompts)  # [M, D]

avg_normal = mean(normal_text_features)  # [1, D]
avg_abnormal = mean(abnormal_text_features)  # [1, D]
```

### å›¾åƒç‰¹å¾ï¼ˆImage Featuresï¼‰
```python
# æå–ä¸‰ä¸ªå±‚æ¬¡çš„ç‰¹å¾
large_scale_tokens  # å¤§å°ºåº¦ç‰¹å¾ (48x48 kernel)
mid_scale_tokens    # ä¸­å°ºåº¦ç‰¹å¾ (32x32 kernel)
patch_tokens        # patchçº§ç‰¹å¾ (16x16)
class_tokens        # å…¨å±€class token
```

---

## 2ï¸âƒ£ å›¾åƒçº§å¼‚å¸¸åˆ†æ•°ï¼ˆImage-Level Scoreï¼‰

### è®¡ç®—æ–¹æ³•
```python
# 1. ä½¿ç”¨class tokenä¸æ–‡æœ¬ç‰¹å¾è®¡ç®—ç›¸ä¼¼åº¦
zscore = compute_score(class_tokens, [avg_normal, avg_abnormal])
# zscore.shape = [batch, 1, 2]
# zscore[:, 0, 0] = P(normal | image)
# zscore[:, 0, 1] = P(abnormal | image)

# 2. å›¾åƒçº§å¼‚å¸¸åˆ†æ•° = P(abnormal | image)
z0score = zscore[:, 0, 1]  # [batch]
```

### compute_scoreå‡½æ•°
```python
def compute_score(image_features, text_features):
    # å½’ä¸€åŒ–
    image_features = image_features / ||image_features||
    text_features = text_features / ||text_features||
    
    # è®¡ç®—ç›¸ä¼¼åº¦å¹¶softmax
    similarity = (image_features @ text_features.T) / 0.07
    probs = softmax(similarity, dim=-1)
    
    return probs
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨æ¸©åº¦ç³»æ•° `0.07` æ¥æ”¾å¤§ç›¸ä¼¼åº¦å·®å¼‚
- softmaxç¡®ä¿ P(normal) + P(abnormal) = 1
- **z0score è¶Šå¤§ï¼Œè¯´æ˜å›¾åƒè¶Šå¼‚å¸¸**

---

## 3ï¸âƒ£ åƒç´ çº§å¼‚å¸¸åˆ†æ•°ï¼ˆPixel-Level Scoreï¼‰

### å¤šå°ºåº¦ç‰¹å¾ç›¸ä¼¼åº¦
```python
# 1. è®¡ç®—æ¯ä¸ªpatchä¸abnormalæ–‡æœ¬çš„ç›¸ä¼¼åº¦
large_scale_similarity = compute_sim(large_scale_tokens, [avg_normal, avg_abnormal])[:, :, 1]
mid_scale_similarity = compute_sim(mid_scale_tokens, [avg_normal, avg_abnormal])[:, :, 1]

# 2. è°ƒå’Œèšåˆï¼ˆHarmonic Aggregationï¼‰
large_scale_score = harmonic_aggregation(large_scale_similarity, large_scale_mask)
mid_scale_score = harmonic_aggregation(mid_scale_similarity, mid_scale_mask)

# 3. å¤šå°ºåº¦èåˆï¼ˆè°ƒå’Œå¹³å‡ï¼‰
multiscale_score = 3.0 / (1.0/large_scale_score + 1.0/mid_scale_score + 1.0/z0score)

# 4. ä¸Šé‡‡æ ·åˆ°åŸå§‹åˆ†è¾¨ç‡
anomaly_map = F.interpolate(multiscale_score, size=(H, W), mode='bilinear')
```

### è°ƒå’Œèšåˆï¼ˆHarmonic Aggregationï¼‰
```python
def harmonic_aggregation(similarity, mask):
    """
    å¯¹äºæ¯ä¸ªä½ç½®çš„patchï¼Œè®¡ç®—å…¶åœ¨å¤šä¸ªçª—å£ä¸­çš„è°ƒå’Œå¹³å‡
    
    Args:
        similarity: æ¯ä¸ªpatchä¸abnormalçš„ç›¸ä¼¼åº¦ [batch, num_patches]
        mask: æ¯ä¸ªçª—å£åŒ…å«å“ªäº›patch
    
    Returns:
        score: æ¯ä¸ªä½ç½®çš„å¼‚å¸¸åˆ†æ•° [batch, H, W]
    """
    for each_position_idx in range(H*W):
        # æ‰¾åˆ°åŒ…å«è¯¥ä½ç½®çš„æ‰€æœ‰çª—å£
        windows_containing_position = mask[position_idx]
        
        # è®¡ç®—è°ƒå’Œå¹³å‡
        n = len(windows_containing_position)
        harmonic_mean = n / sum(1.0 / similarity[windows_containing_position])
        
        score[position_idx] = harmonic_mean
    
    return score.reshape(batch, H, W)
```

**ä¸ºä»€ä¹ˆä½¿ç”¨è°ƒå’Œå¹³å‡ï¼Ÿ**
- è°ƒå’Œå¹³å‡å¯¹å¼‚å¸¸å€¼æ›´æ•æ„Ÿ
- å¦‚æœä¸€ä¸ªåŒºåŸŸåœ¨ä»»ä½•çª—å£ä¸­æ˜¾ç¤ºå¼‚å¸¸ï¼Œåˆ†æ•°ä¼šæ›´é«˜
- æ¯”ç®—æœ¯å¹³å‡æ›´é€‚åˆå¼‚å¸¸æ£€æµ‹

---

## 4ï¸âƒ£ è¯„ä¼°æŒ‡æ ‡

### å›¾åƒçº§æŒ‡æ ‡ï¼ˆImage-Level Metricsï¼‰

#### AUROC-SP (Sample-level AUROC)
```python
# Ground Truth: gt_sp = [0, 1, 0, 1, ...]  (0=æ­£å¸¸, 1=å¼‚å¸¸)
# Prediction: pr_sp = z0score  (å¼‚å¸¸åˆ†æ•°)

auroc_sp = roc_auc_score(gt_sp, pr_sp)
```
- **å«ä¹‰**ï¼šåˆ¤æ–­æ•´å¼ å›¾ç‰‡æ˜¯å¦å¼‚å¸¸çš„èƒ½åŠ›
- **å€¼åŸŸ**ï¼š0-1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½
- **0.5** = éšæœºçŒœæµ‹

#### AP-SP (Sample-level Average Precision)
```python
ap_sp = average_precision_score(gt_sp, pr_sp)
```
- **å«ä¹‰**ï¼šprecision-recallæ›²çº¿ä¸‹é¢ç§¯
- **å€¼åŸŸ**ï¼š0-1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

#### F1-SP (Sample-level F1 Score)
```python
precisions, recalls, thresholds = precision_recall_curve(gt_sp, pr_sp)
f1_scores = 2 * precisions * recalls / (precisions + recalls)
f1_sp = max(f1_scores)  # å–æœ€ä½³F1
```
- **å«ä¹‰**ï¼šprecisionå’Œrecallçš„è°ƒå’Œå¹³å‡
- **è®¡ç®—**ï¼šF1 = 2 * P * R / (P + R)
- **å€¼åŸŸ**ï¼š0-1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

---

### åƒç´ çº§æŒ‡æ ‡ï¼ˆPixel-Level Metricsï¼‰

#### AUROC-PX (Pixel-level AUROC)
```python
# Ground Truth: gt_px = [[0,0,1,1,...], ...]  æ¯ä¸ªåƒç´ çš„æ ‡ç­¾
# Prediction: pr_px = anomaly_map  æ¯ä¸ªåƒç´ çš„å¼‚å¸¸åˆ†æ•°

auroc_px = roc_auc_score(gt_px.ravel(), pr_px.ravel())
```
- **å«ä¹‰**ï¼šåˆ¤æ–­æ¯ä¸ªåƒç´ æ˜¯å¦å¼‚å¸¸çš„èƒ½åŠ›
- **å€¼åŸŸ**ï¼š0-1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

#### AP-PX (Pixel-level Average Precision)
```python
ap_px = average_precision_score(gt_px.ravel(), pr_px.ravel())
```

#### F1-PX (Pixel-level F1 Score)
```python
precisions, recalls, thresholds = precision_recall_curve(gt_px.ravel(), pr_px.ravel())
f1_scores = 2 * precisions * recalls / (precisions + recalls)
f1_px = max(f1_scores)
```

#### AU-PRO (Area Under Per-Region-Overlap)
```python
def cal_pro_score(masks, amaps, max_step=200, expect_fpr=0.3):
    """
    è®¡ç®—æ¯ä¸ªgtåŒºåŸŸçš„é‡å ç‡
    
    æµç¨‹ï¼š
    1. å¯¹äºä¸åŒé˜ˆå€¼ï¼Œå°†anomaly_mapäºŒå€¼åŒ–
    2. å¯¹äºæ¯ä¸ªgtå¼‚å¸¸åŒºåŸŸï¼š
       - è®¡ç®—è¯¥åŒºåŸŸå†…æœ‰å¤šå°‘åƒç´ è¢«æ­£ç¡®é¢„æµ‹
       - overlap = TP_pixels / region_area
    3. è®¡ç®—æ‰€æœ‰åŒºåŸŸçš„å¹³å‡overlap
    4. åœ¨FPR < 0.3çš„èŒƒå›´å†…è®¡ç®—AUC
    """
    binary_amaps = amaps > threshold
    
    for each_gt_region in gt_masks:
        tp_pixels = count(binary_amaps AND gt_region)
        overlap = tp_pixels / region.area
    
    avg_overlap = mean(all_overlaps)
    
    # è®¡ç®—æ›²çº¿ä¸‹é¢ç§¯ï¼ˆFPR < 0.3ï¼‰
    aupro = auc(fprs, avg_overlaps)
    return aupro
```
- **å«ä¹‰**ï¼šæ£€æµ‹åˆ°çœŸå®å¼‚å¸¸åŒºåŸŸçš„èƒ½åŠ›
- **ä¼˜åŠ¿**ï¼šè€ƒè™‘äº†åŒºåŸŸçš„å®Œæ•´æ€§ï¼Œä¸åªæ˜¯åƒç´ å‡†ç¡®ç‡
- **å€¼åŸŸ**ï¼š0-1ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½

---

## 5ï¸âƒ£ å¦‚ä½•åˆ¤æ–­æ­£å¸¸/å¼‚å¸¸

### å›¾åƒçº§åˆ¤æ–­
```python
if z0score > threshold:
    label = "å¼‚å¸¸"
else:
    label = "æ­£å¸¸"
```

**thresholdé€‰æ‹©**ï¼š
- é€šå¸¸åœ¨éªŒè¯é›†ä¸Šé€‰æ‹©ä½¿F1æœ€å¤§çš„é˜ˆå€¼
- å¸¸ç”¨å€¼ï¼š0.5 - 0.7
- å¯ä»¥æ ¹æ®ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ï¼ˆåä¿å®ˆ vs åæ•æ„Ÿï¼‰

### åƒç´ çº§åˆ¤æ–­
```python
# å¯¹anomaly_mapåº”ç”¨é˜ˆå€¼
binary_mask = anomaly_map > threshold

# å½¢æ€å­¦å¤„ç†ï¼ˆå»å™ªã€å¹³æ»‘ï¼‰
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

# è¿é€šåŸŸåˆ†æ
num_labels, labels = cv2.connectedComponents(binary_mask)

# è¿‡æ»¤å°åŒºåŸŸ
for region in regions:
    if region.area < min_area:
        remove(region)
```

---

## 6ï¸âƒ£ å®Œæ•´æµç¨‹ç¤ºæ„å›¾

```
è¾“å…¥å›¾åƒ
   â†“
CLIPç¼–ç 
   â”œâ”€â†’ class_token â”€â†’ z0score (å›¾åƒçº§åˆ†æ•°)
   â”œâ”€â†’ large_scale_tokens â”€â”
   â”œâ”€â†’ mid_scale_tokens â”€â”€â”€â”¼â”€â†’ å¤šå°ºåº¦èåˆ â”€â†’ anomaly_map (åƒç´ çº§åˆ†æ•°)
   â””â”€â†’ patch_tokens â”€â”€â”€â”€â”€â”€â”€â”˜
   
æ–‡æœ¬ç¼–ç 
   â”œâ”€â†’ "normal" prompts â”€â†’ avg_normal
   â””â”€â†’ "abnormal" prompts â”€â†’ avg_abnormal

ç›¸ä¼¼åº¦è®¡ç®—
   image_features @ text_features â”€â†’ similarity
   
è°ƒå’Œèšåˆ
   å¤šçª—å£è°ƒå’Œå¹³å‡ â”€â†’ robustness

é˜ˆå€¼åˆ†å‰²
   anomaly_map > threshold â”€â†’ binary_mask
   
å½¢æ€å­¦å¤„ç†
   å»å™ª + å¹³æ»‘ â”€â†’ clean_mask
   
è¿é€šåŸŸåˆ†æ
   åˆ†ç¦»å¤šä¸ªåŒºåŸŸ â”€â†’ regions
   
è¾“å‡º
   â”œâ”€â†’ z0score (å¼‚å¸¸åˆ†æ•°)
   â”œâ”€â†’ anomaly_map (å¼‚å¸¸å›¾)
   â””â”€â†’ regions (åˆ†å‰²åŒºåŸŸ)
```

---

## 7ï¸âƒ£ å…³é”®å‚æ•°å½±å“

| å‚æ•° | ä½œç”¨ | å½±å“ |
|------|------|------|
| **threshold** | å¼‚å¸¸åˆ¤å®šé˜ˆå€¼ | è¶Šä½è¶Šæ•æ„Ÿï¼Œè¶Šé«˜è¶Šä¿å®ˆ |
| **temperature (0.07)** | ç›¸ä¼¼åº¦æ¸©åº¦ç³»æ•° | è¶Šå°å·®å¼‚è¶Šæ˜æ˜¾ |
| **min_area** | æœ€å°åŒºåŸŸé¢ç§¯ | è¿‡æ»¤å™ªå£°åŒºåŸŸ |
| **kernel_size** | å¤šå°ºåº¦çª—å£å¤§å° | å½±å“æ„Ÿå—é‡ |

---

## ğŸ’¡ æ€»ç»“

1. **å›¾åƒçº§å¼‚å¸¸æ£€æµ‹**ï¼š
   - ä½¿ç”¨ class token ä¸æ–‡æœ¬ç‰¹å¾çš„ç›¸ä¼¼åº¦
   - z0score = P(abnormal | image)
   - é˜ˆå€¼é€šå¸¸ 0.5-0.7

2. **åƒç´ çº§å¼‚å¸¸åˆ†å‰²**ï¼š
   - å¤šå°ºåº¦patchç‰¹å¾ + è°ƒå’Œèšåˆ
   - ç”Ÿæˆæ¯ä¸ªåƒç´ çš„å¼‚å¸¸åˆ†æ•°å›¾
   - é˜ˆå€¼åˆ†å‰² + å½¢æ€å­¦å¤„ç† + è¿é€šåŸŸåˆ†æ

3. **è¯„ä¼°æŒ‡æ ‡**ï¼š
   - **AUROC**ï¼šåˆ†ç±»èƒ½åŠ›ï¼ˆå›¾åƒçº§/åƒç´ çº§ï¼‰
   - **F1 Score**ï¼šprecisionå’Œrecallçš„å¹³è¡¡
   - **AP**ï¼šprecision-recallæ›²çº¿ä¸‹é¢ç§¯
   - **AU-PRO**ï¼šåŒºåŸŸæ£€æµ‹èƒ½åŠ›

4. **ä¼˜åŠ¿**ï¼š
   - âœ… é›¶æ ·æœ¬/å°‘æ ·æœ¬å­¦ä¹ 
   - âœ… å¤šå°ºåº¦ç‰¹å¾èåˆ
   - âœ… è°ƒå’Œèšåˆæé«˜é²æ£’æ€§
   - âœ… æ”¯æŒå¤šç§ç‰©ä½“ç±»åˆ«

---

**ğŸ”— å‚è€ƒè®ºæ–‡**ï¼š
*WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation (CVPR 2023)*

