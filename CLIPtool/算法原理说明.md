# WinCLIP 算法原理说明

## 📊 异常检测流程概述

WinCLIP使用CLIP模型进行零样本/少样本异常检测，主要包括以下步骤：

---

## 1️⃣ 特征提取

### 文本特征（Text Features）
```python
# 为每个类别生成两种描述
normal_prompts = [
    "flawless bottle", 
    "perfect bottle",
    "bottle without defect",
    ...
]

abnormal_prompts = [
    "damaged bottle",
    "bottle with flaw",
    "bottle with defect",
    ...
]

# 提取文本特征并平均
normal_text_features = CLIP.encode_text(normal_prompts)  # [N, D]
abnormal_text_features = CLIP.encode_text(abnormal_prompts)  # [M, D]

avg_normal = mean(normal_text_features)  # [1, D]
avg_abnormal = mean(abnormal_text_features)  # [1, D]
```

### 图像特征（Image Features）
```python
# 提取三个层次的特征
large_scale_tokens  # 大尺度特征 (48x48 kernel)
mid_scale_tokens    # 中尺度特征 (32x32 kernel)
patch_tokens        # patch级特征 (16x16)
class_tokens        # 全局class token
```

---

## 2️⃣ 图像级异常分数（Image-Level Score）

### 计算方法
```python
# 1. 使用class token与文本特征计算相似度
zscore = compute_score(class_tokens, [avg_normal, avg_abnormal])
# zscore.shape = [batch, 1, 2]
# zscore[:, 0, 0] = P(normal | image)
# zscore[:, 0, 1] = P(abnormal | image)

# 2. 图像级异常分数 = P(abnormal | image)
z0score = zscore[:, 0, 1]  # [batch]
```

### compute_score函数
```python
def compute_score(image_features, text_features):
    # 归一化
    image_features = image_features / ||image_features||
    text_features = text_features / ||text_features||
    
    # 计算相似度并softmax
    similarity = (image_features @ text_features.T) / 0.07
    probs = softmax(similarity, dim=-1)
    
    return probs
```

**关键点**：
- 使用温度系数 `0.07` 来放大相似度差异
- softmax确保 P(normal) + P(abnormal) = 1
- **z0score 越大，说明图像越异常**

---

## 3️⃣ 像素级异常分数（Pixel-Level Score）

### 多尺度特征相似度
```python
# 1. 计算每个patch与abnormal文本的相似度
large_scale_similarity = compute_sim(large_scale_tokens, [avg_normal, avg_abnormal])[:, :, 1]
mid_scale_similarity = compute_sim(mid_scale_tokens, [avg_normal, avg_abnormal])[:, :, 1]

# 2. 调和聚合（Harmonic Aggregation）
large_scale_score = harmonic_aggregation(large_scale_similarity, large_scale_mask)
mid_scale_score = harmonic_aggregation(mid_scale_similarity, mid_scale_mask)

# 3. 多尺度融合（调和平均）
multiscale_score = 3.0 / (1.0/large_scale_score + 1.0/mid_scale_score + 1.0/z0score)

# 4. 上采样到原始分辨率
anomaly_map = F.interpolate(multiscale_score, size=(H, W), mode='bilinear')
```

### 调和聚合（Harmonic Aggregation）
```python
def harmonic_aggregation(similarity, mask):
    """
    对于每个位置的patch，计算其在多个窗口中的调和平均
    
    Args:
        similarity: 每个patch与abnormal的相似度 [batch, num_patches]
        mask: 每个窗口包含哪些patch
    
    Returns:
        score: 每个位置的异常分数 [batch, H, W]
    """
    for each_position_idx in range(H*W):
        # 找到包含该位置的所有窗口
        windows_containing_position = mask[position_idx]
        
        # 计算调和平均
        n = len(windows_containing_position)
        harmonic_mean = n / sum(1.0 / similarity[windows_containing_position])
        
        score[position_idx] = harmonic_mean
    
    return score.reshape(batch, H, W)
```

**为什么使用调和平均？**
- 调和平均对异常值更敏感
- 如果一个区域在任何窗口中显示异常，分数会更高
- 比算术平均更适合异常检测

---

## 4️⃣ 评估指标

### 图像级指标（Image-Level Metrics）

#### AUROC-SP (Sample-level AUROC)
```python
# Ground Truth: gt_sp = [0, 1, 0, 1, ...]  (0=正常, 1=异常)
# Prediction: pr_sp = z0score  (异常分数)

auroc_sp = roc_auc_score(gt_sp, pr_sp)
```
- **含义**：判断整张图片是否异常的能力
- **值域**：0-1，越接近1越好
- **0.5** = 随机猜测

#### AP-SP (Sample-level Average Precision)
```python
ap_sp = average_precision_score(gt_sp, pr_sp)
```
- **含义**：precision-recall曲线下面积
- **值域**：0-1，越接近1越好

#### F1-SP (Sample-level F1 Score)
```python
precisions, recalls, thresholds = precision_recall_curve(gt_sp, pr_sp)
f1_scores = 2 * precisions * recalls / (precisions + recalls)
f1_sp = max(f1_scores)  # 取最佳F1
```
- **含义**：precision和recall的调和平均
- **计算**：F1 = 2 * P * R / (P + R)
- **值域**：0-1，越接近1越好

---

### 像素级指标（Pixel-Level Metrics）

#### AUROC-PX (Pixel-level AUROC)
```python
# Ground Truth: gt_px = [[0,0,1,1,...], ...]  每个像素的标签
# Prediction: pr_px = anomaly_map  每个像素的异常分数

auroc_px = roc_auc_score(gt_px.ravel(), pr_px.ravel())
```
- **含义**：判断每个像素是否异常的能力
- **值域**：0-1，越接近1越好

#### AP-PX (Pixel-level Average Precision)
```python
ap_px = average_precision_score(gt_px.ravel(), pr_px.ravel())
```

#### F1-PX (Pixel-level F1 Score)
```python
precisions, recalls, thresholds = precision_recall_curve(gt_px.ravel(), pr_px.ravel())
f1_scores = 2 * precisions * recalls / (precisions + recalls)
f1_px = max(f1_scores)
```

#### AU-PRO (Area Under Per-Region-Overlap)
```python
def cal_pro_score(masks, amaps, max_step=200, expect_fpr=0.3):
    """
    计算每个gt区域的重叠率
    
    流程：
    1. 对于不同阈值，将anomaly_map二值化
    2. 对于每个gt异常区域：
       - 计算该区域内有多少像素被正确预测
       - overlap = TP_pixels / region_area
    3. 计算所有区域的平均overlap
    4. 在FPR < 0.3的范围内计算AUC
    """
    binary_amaps = amaps > threshold
    
    for each_gt_region in gt_masks:
        tp_pixels = count(binary_amaps AND gt_region)
        overlap = tp_pixels / region.area
    
    avg_overlap = mean(all_overlaps)
    
    # 计算曲线下面积（FPR < 0.3）
    aupro = auc(fprs, avg_overlaps)
    return aupro
```
- **含义**：检测到真实异常区域的能力
- **优势**：考虑了区域的完整性，不只是像素准确率
- **值域**：0-1，越接近1越好

---

## 5️⃣ 如何判断正常/异常

### 图像级判断
```python
if z0score > threshold:
    label = "异常"
else:
    label = "正常"
```

**threshold选择**：
- 通常在验证集上选择使F1最大的阈值
- 常用值：0.5 - 0.7
- 可以根据业务需求调整（偏保守 vs 偏敏感）

### 像素级判断
```python
# 对anomaly_map应用阈值
binary_mask = anomaly_map > threshold

# 形态学处理（去噪、平滑）
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

# 连通域分析
num_labels, labels = cv2.connectedComponents(binary_mask)

# 过滤小区域
for region in regions:
    if region.area < min_area:
        remove(region)
```

---

## 6️⃣ 完整流程示意图

```
输入图像
   ↓
CLIP编码
   ├─→ class_token ─→ z0score (图像级分数)
   ├─→ large_scale_tokens ─┐
   ├─→ mid_scale_tokens ───┼─→ 多尺度融合 ─→ anomaly_map (像素级分数)
   └─→ patch_tokens ───────┘
   
文本编码
   ├─→ "normal" prompts ─→ avg_normal
   └─→ "abnormal" prompts ─→ avg_abnormal

相似度计算
   image_features @ text_features ─→ similarity
   
调和聚合
   多窗口调和平均 ─→ robustness

阈值分割
   anomaly_map > threshold ─→ binary_mask
   
形态学处理
   去噪 + 平滑 ─→ clean_mask
   
连通域分析
   分离多个区域 ─→ regions
   
输出
   ├─→ z0score (异常分数)
   ├─→ anomaly_map (异常图)
   └─→ regions (分割区域)
```

---

## 7️⃣ 关键参数影响

| 参数 | 作用 | 影响 |
|------|------|------|
| **threshold** | 异常判定阈值 | 越低越敏感，越高越保守 |
| **temperature (0.07)** | 相似度温度系数 | 越小差异越明显 |
| **min_area** | 最小区域面积 | 过滤噪声区域 |
| **kernel_size** | 多尺度窗口大小 | 影响感受野 |

---

## 💡 总结

1. **图像级异常检测**：
   - 使用 class token 与文本特征的相似度
   - z0score = P(abnormal | image)
   - 阈值通常 0.5-0.7

2. **像素级异常分割**：
   - 多尺度patch特征 + 调和聚合
   - 生成每个像素的异常分数图
   - 阈值分割 + 形态学处理 + 连通域分析

3. **评估指标**：
   - **AUROC**：分类能力（图像级/像素级）
   - **F1 Score**：precision和recall的平衡
   - **AP**：precision-recall曲线下面积
   - **AU-PRO**：区域检测能力

4. **优势**：
   - ✅ 零样本/少样本学习
   - ✅ 多尺度特征融合
   - ✅ 调和聚合提高鲁棒性
   - ✅ 支持多种物体类别

---

**🔗 参考论文**：
*WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation (CVPR 2023)*

